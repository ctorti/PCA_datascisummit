{
  "cells": [
    {
      "cell_type": "code", 
      "execution_count": 0, 
      "metadata": {
        "collapsed": false, 
        "deletable": true, 
        "editable": true
      }, 
      "outputs": [], 
      "source": [
        "# this is so that this notebook works in both Python 2.7 and 3.x\n", 
        "from __future__ import print_function, division"
      ]
    }, 
    {
      "cell_type": "markdown", 
      "metadata": {
        "deletable": true, 
        "editable": true
      }, 
      "source": [
        "## Principal Component Analysis \n", 
        "\n", 
        "In this module, you will be using Scikit-Learn, Pandas and Numpy. Start by loading \n", 
        "\n", 
        "* `numpy` as `np`\n", 
        "* `pandas` as `pd`\n", 
        "* from the `sklearn` library and specifically from `sklearn.decomposition` import the `PCA` class"
      ]
    }, 
    {
      "cell_type": "code", 
      "execution_count": 0, 
      "metadata": {
        "collapsed": false, 
        "deletable": true, 
        "editable": true
      }, 
      "outputs": [], 
      "source": [
        "import numpy as np\n", 
        "import pandas as pd\n", 
        "from sklearn.decomposition import PCA"
      ]
    }, 
    {
      "cell_type": "markdown", 
      "metadata": {
        "deletable": true, 
        "editable": true
      }, 
      "source": [
        "You will also be interested in visualising some of the results, load\n", 
        "\n", 
        "* `matplotlib.pylab` as `plt`\n", 
        "* don't forget to add the line `%matplotlib inline` so that the plots are displayed in this notebook\n", 
        "* `seaborn` as `sns`"
      ]
    }, 
    {
      "cell_type": "code", 
      "execution_count": 0, 
      "metadata": {
        "collapsed": true, 
        "deletable": true, 
        "editable": true
      }, 
      "outputs": [], 
      "source": [
        "import matplotlib.pylab as plt\n", 
        "%matplotlib inline\n", 
        "import seaborn as sns"
      ]
    }, 
    {
      "cell_type": "markdown", 
      "metadata": {
        "deletable": true, 
        "editable": true
      }, 
      "source": [
        "### Learning Activity - Apply PCA in the input data using scikit-learn\n", 
        "\n", 
        "In scikit-learn, the usual methodology is:\n", 
        "\n", 
        "* instantiate an object from the class associated to the method of interest (e.g.: PCA)\n", 
        "* apply a `.fit` or `.fit_transform` method to train the model\n", 
        "* apply a `.predict` method (if relevant)\n", 
        "\n", 
        "More information about the PCA object in sklearn can be found there: http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\n", 
        "\n", 
        "Before starting, you need to load the dataset `customers` from `data/online_retail_afterEDA.csv`. "
      ]
    }, 
    {
      "cell_type": "code", 
      "execution_count": 0, 
      "metadata": {
        "collapsed": false, 
        "deletable": true, 
        "editable": true
      }, 
      "outputs": [], 
      "source": [
        "customers = pd.read_csv(\"data/online_retail_afterEDA.csv\",\n", 
        "                        index_col = \"CustomerID\")\n", 
        "customers.head()"
      ]
    }, 
    {
      "cell_type": "markdown", 
      "metadata": {
        "deletable": true, 
        "editable": true
      }, 
      "source": [
        "Select the continuous features (PCA is not meant to work with other types of variables). The continuous variables are\n", 
        "\n", 
        "```python\n", 
        "['balance', 'max_spent', 'mean_spent', 'min_spent', \n", 
        "'n_orders', 'total_items', 'total_items_returned', \n", 
        "'total_refunded', 'total_spent']\n", 
        "```\n", 
        "\n", 
        "Call the resulting dataframe `customers` still. Let's also save the last column (has returned or not) which you will use later on. Call that `has_returned`."
      ]
    }, 
    {
      "cell_type": "code", 
      "execution_count": 0, 
      "metadata": {
        "collapsed": false, 
        "deletable": true, 
        "editable": true
      }, 
      "outputs": [], 
      "source": [
        "continuous_features = ['balance', 'max_spent', 'mean_spent',\n", 
        "                    'min_spent', 'n_orders', 'total_items', \n", 
        "                    'total_items_returned', 'total_refunded', \n", 
        "                    'total_spent']\n", 
        "\n", 
        "has_returned = customers['has_returned']\n", 
        "customers = customers[continuous_features]\n", 
        "customers.head()"
      ]
    }, 
    {
      "cell_type": "markdown", 
      "metadata": {}, 
      "source": [
        "#### Getting started with PCA\n", 
        "\n", 
        "You can now initialise a PCA object and create an index for each Principal Component:"
      ]
    }, 
    {
      "cell_type": "code", 
      "execution_count": 0, 
      "metadata": {
        "collapsed": false, 
        "deletable": true, 
        "editable": true
      }, 
      "outputs": [], 
      "source": [
        "# ..add your code here..\n"
      ]
    }, 
    {
      "cell_type": "markdown", 
      "metadata": {
        "deletable": true, 
        "editable": true
      }, 
      "source": [
        "The values of the Principal Components (scores) can be computed by the `fit_transform()` (alternatively, `fit()` followed by `transform()`) function. This function returns a matrix with the principal components, where the first column in the matrix contains the first principal component, the second column the second component, and so on."
      ]
    }, 
    {
      "cell_type": "code", 
      "execution_count": 0, 
      "metadata": {
        "collapsed": false, 
        "deletable": true, 
        "editable": true
      }, 
      "outputs": [], 
      "source": [
        "# Create the PCA scores matrix and check the dimensionality\n"
      ]
    }, 
    {
      "cell_type": "markdown", 
      "metadata": {
        "deletable": true, 
        "editable": true
      }, 
      "source": [
        "The loadings for the principal components are stored in a named element *components_*. This contains a matrix with the loadings of each principal component, where the first column in the matrix contains the loadings for the first principal component, the second column contains the loadings for the second principal component, and so on. "
      ]
    }, 
    {
      "cell_type": "code", 
      "execution_count": 0, 
      "metadata": {
        "collapsed": false, 
        "deletable": true, 
        "editable": true
      }, 
      "outputs": [], 
      "source": [
        "# Create the PCA loadings matrix and check the dimensionality\n"
      ]
    }, 
    {
      "cell_type": "markdown", 
      "metadata": {
        "deletable": true, 
        "editable": true
      }, 
      "source": [
        "### Learning Activity: Calculate and plot the explained and cumulative variance \n", 
        "\n", 
        "But how much information have we lost? We can figure this out by looking at the explained and cumulative variance. The explained variance gives us the proportion of variance explained by each successive Principal Component. The cumulative variance  is obtained by adding the successive proportions of explained variance to obtain the total sum."
      ]
    }, 
    {
      "cell_type": "code", 
      "execution_count": 0, 
      "metadata": {
        "collapsed": false, 
        "deletable": true, 
        "editable": true
      }, 
      "outputs": [], 
      "source": [
        "# Calculate the explained variance\n", 
        "\n", 
        "# Calculate the cumulative variance\n", 
        "\n", 
        "# Combine both in a data frame\n"
      ]
    }, 
    {
      "cell_type": "markdown", 
      "metadata": {
        "deletable": true, 
        "editable": true
      }, 
      "source": [
        "We can also plot the explained variance using a barplot with seaborn:"
      ]
    }, 
    {
      "cell_type": "code", 
      "execution_count": 0, 
      "metadata": {
        "collapsed": false, 
        "deletable": true, 
        "editable": true
      }, 
      "outputs": [], 
      "source": [
        "# Plot the explained variance per PC using a barplot\n"
      ]
    }, 
    {
      "cell_type": "markdown", 
      "metadata": {}, 
      "source": [
        "#### Bonus: cumulative variance\n", 
        "\n", 
        "As a bonus, can you compute the cumulative explained variance? and can you plot it using a barplot?"
      ]
    }, 
    {
      "cell_type": "code", 
      "execution_count": 0, 
      "metadata": {
        "collapsed": false
      }, 
      "outputs": [], 
      "source": [
        "# ..add your code here..\n"
      ]
    }, 
    {
      "cell_type": "markdown", 
      "metadata": {
        "deletable": true, 
        "editable": true
      }, 
      "source": [
        "### Test Activity - Reading in the associated classes \n", 
        "\n", 
        "At this stage, we will import and join per row with the `customers` DataFrame the associated classes in order to use this knowledge during visualisation. Try to import the customer classes from the provided \"`customer_classes.csv`\" into the variable **_y_**. Remember to also define the column that will be used as the row labels of the DataFrame as in the previous step (if you are unsure, open the csv file and try to decide the column name you are going to use). \n", 
        "\n", 
        "In this case, the class **_y_** contains two classes (binary case) - \"yes\" vs. \"no\" - that represent the returning and non-returning customers respectively."
      ]
    }, 
    {
      "cell_type": "markdown", 
      "metadata": {
        "deletable": true, 
        "editable": true
      }, 
      "source": [
        "### Learning Activity - Joining with class\n", 
        "\n", 
        "A very useful feature of `pandas` is its `join()` function, which allows combining tables based on one column shared between tables. Here we use `join()` to combine the input features and information on whether customers return (associated classes).\n", 
        "\n", 
        "You will join the class labels with the dataset by a shared index. **`CustomerID`** is the obvious choice here, as it is the only column shared between the two DataFrames."
      ]
    }, 
    {
      "cell_type": "code", 
      "execution_count": 0, 
      "metadata": {
        "collapsed": false, 
        "deletable": true, 
        "editable": true
      }, 
      "outputs": [], 
      "source": [
        "# Join the PCA scores and y DataFrames based on the common CustomerIDs\n"
      ]
    }, 
    {
      "cell_type": "markdown", 
      "metadata": {
        "deletable": true, 
        "editable": true
      }, 
      "source": [
        "### Learning Activity - Export to csv\n", 
        "\n", 
        "Now that we have produced datasets that are ready for applying some machine learning algorithms we will save (or \"export\") them to our local machine and working repository. This also serves as a checkpoint for the bootcamp so that you can get started straight away with the next module even if you got stuck in some part above.\n", 
        "\n", 
        "Writing a `pd.Dataframe` to disk is very easy - you just use the `.to_csv()` method, and specify the file path to where you want it saved. There also other [formats](http://pandas.pydata.org/pandas-docs/stable/api.html#id12) that you save to, which are based on functions that work in exactly the same way."
      ]
    }, 
    {
      "cell_type": "code", 
      "execution_count": 0, 
      "metadata": {
        "collapsed": false, 
        "deletable": true, 
        "editable": true
      }, 
      "outputs": [], 
      "source": [
        "# Save to a csv file with the '.to_csv()' method \n", 
        "# and give the file a name you want\n"
      ]
    }
  ], 
  "metadata": {
    "anaconda-cloud": {}, 
    "kernelspec": {
      "display_name": "Python 3", 
      "language": "python", 
      "name": "python3"
    }, 
    "language_info": {
      "codemirror_mode": {
        "name": "ipython", 
        "version": 3
      }, 
      "file_extension": ".py", 
      "mimetype": "text/x-python", 
      "name": "python", 
      "nbconvert_exporter": "python", 
      "pygments_lexer": "ipython3", 
      "version": "3.6.0"
    }
  }, 
  "nbformat": 4, 
  "nbformat_minor": 1
}